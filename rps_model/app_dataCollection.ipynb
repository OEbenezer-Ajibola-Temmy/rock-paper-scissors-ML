{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Relevant Notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import itertools \n",
    "import random\n",
    "import os \n",
    "\n",
    "import csv \n",
    "from collections import Counter \n",
    "from collections import deque\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to be implemented \n",
    "\n",
    "1. Access webcam with Opencv\n",
    "2. Use mediapipe to process this data and extract the needed landmarks \n",
    "3. Train this data with N-Net \n",
    "4. Test the trained results\n",
    "5. Pass static images to the classifier \n",
    "\n",
    "WEBCAM -> MEDIAPIPE LMs -> Preprocessed LMS -> MODEL Classifier -> Rock, paper scissors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe hand tools \n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save dataset \n",
    "save_dir = 'hand_landmarks'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_landmarks = 3000  \n",
    "test_landmarks = 200 \n",
    "images_per_class = total_landmarks // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List to store landmarks together with labels\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mp_hands.Hands(static_image_mode= False, max_num_hands=2, min_detection_confidence=0.45) as hands:\n",
    "    while True: \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False \n",
    "        results = hands.process(image)\n",
    "        \n",
    "        image.flags.writeable = True \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # Drawing the hand landmarks \n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks\n",
    "                                          , mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                image_height, image_width, _ = image.shape\n",
    "                \n",
    "                landmark_list = []\n",
    "                \n",
    "                for landmark in hand_landmarks.landmark: \n",
    "                    landmark_x = landmark.x * image_width\n",
    "                    landmark_y = landmark.y * image_height\n",
    "                    \n",
    "                    landmark_list.extend([landmark_x, landmark_y, landmark.z])\n",
    "                landmarks.append(landmark_list)\n",
    "                print(landmarks)\n",
    "        \n",
    "        cv2.imshow('Rock Paper Scissors Classifier', image)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('r') and labels.count(0) <= images_per_class:\n",
    "            \n",
    "            labels.append(0)\n",
    "            if labels.count(0) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'rock_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Rock Hand Landmark successfully!\")\n",
    "                \n",
    "        elif key == ord('p') and labels.count(1) <= images_per_class:\n",
    "            \n",
    "            labels.append(1)\n",
    "            \n",
    "            if labels.count(1) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'paper_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Paper Hand Landmark successfully!\")\n",
    "                \n",
    "        if key == ord('s') and labels.count(2) <= images_per_class:\n",
    "            \n",
    "            labels.append(2)\n",
    "            \n",
    "            if labels.count(2) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'scissors_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Scissors Hand Landmark successfully!\")\n",
    "            \n",
    "        if len(labels) >= total_landmarks:\n",
    "            break\n",
    "        \n",
    "        if key == ord('x'): \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you carry out the appropriate preprocessing steps for the javascript mediapipe\n",
    "\n",
    "1. Normalizing and making a single array: Multiply the landmark x and y with the image width and heigth.\n",
    "2. Divide the array by largest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_landmarks\\class_0\n",
      "hand_landmarks\\class_1\n",
      "hand_landmarks\\class_2\n"
     ]
    }
   ],
   "source": [
    "for label in range(3):\n",
    "    class_dir = os.path.join(save_dir, 'class_{}'.format(label))\n",
    "    print(class_dir)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        file_path = os.path.join(class_dir, file_name)\n",
    "        landmark = np.load(file_path)\n",
    "        labels.append(label)\n",
    "        data.append(landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.02909546e+02,  3.79377222e+02,  6.51923244e-07,  4.75289841e+02,\n",
       "        3.44713011e+02, -5.01439348e-02,  4.55628281e+02,  3.15184078e+02,\n",
       "       -9.75481942e-02,  4.48804932e+02,  3.19709072e+02, -1.39824569e-01,\n",
       "        4.59203262e+02,  3.40566130e+02, -1.83043689e-01,  5.06900558e+02,\n",
       "        2.82853603e+02, -1.18122481e-01,  5.11560364e+02,  2.59746294e+02,\n",
       "       -1.83783486e-01,  5.14300308e+02,  2.41278048e+02, -2.28936419e-01,\n",
       "        5.20952339e+02,  2.24992790e+02, -2.60434330e-01,  5.40226059e+02,\n",
       "        3.07582998e+02, -1.24198802e-01,  5.35904694e+02,  2.99823704e+02,\n",
       "       -2.02829659e-01,  5.26589470e+02,  2.91400795e+02, -2.40595683e-01,\n",
       "        5.24980049e+02,  2.81757832e+02, -2.59544551e-01,  5.58139381e+02,\n",
       "        3.42417526e+02, -1.30264655e-01,  5.07576523e+02,  3.49927483e+02,\n",
       "       -1.86851174e-01,  4.69041748e+02,  3.52949381e+02, -1.82062641e-01,\n",
       "        4.54035568e+02,  3.49322290e+02, -1.71347201e-01,  5.60443077e+02,\n",
       "        3.76104126e+02, -1.41784504e-01,  5.09989471e+02,  3.81103992e+02,\n",
       "       -1.77780196e-01,  4.77290039e+02,  3.77450724e+02, -1.71830446e-01,\n",
       "        4.64383545e+02,  3.71007128e+02, -1.62630588e-01])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\ssffff\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: .\\assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ssffff\\\\Desktop\\\\One for all\\\\Machine Learning Work\\\\Machine Learning projects\\\\RPS\\\\Model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = tf.saved_model.load('./saved_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
